{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9a5256-37ff-4f94-89a8-372af85d3a0e",
   "metadata": {},
   "source": [
    "### Purpose of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc7af3-2358-404a-b81e-5e69d817a380",
   "metadata": {},
   "source": [
    "This data set is from the well-known UCI Machine Learning Repository. The objective of this notebook is to correctly forecast, based on the provided features, whether or not an adult earns more than $50,000 USD per year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7864b97f-aedc-4497-8777-c091c8405413",
   "metadata": {},
   "source": [
    "### About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620ec83",
   "metadata": {
    "tags": []
   },
   "source": [
    "This data set is from the well-known UCI Machine Learning Repository. The objective of this notebook is to correctly forecast, based on the provided features, whether or not an adult earns more than $50,000 USD per year.\n",
    "\n",
    "The data set selected is “Adult Census Income” attached is the link for easy reference – https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9881d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Age: Describes the age of individuals. Continuous.\n",
    "\n",
    "Workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "\n",
    "fnlwgt: Continuous.\n",
    "\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. education-num: Number of years spent in education. Continuous.\n",
    "\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "\n",
    "sex: Female, Male.\n",
    "\n",
    "capital-gain: Continuous.\n",
    "\n",
    "capital-loss: Continuous.\n",
    "\n",
    "hours-per-week: Continuous.\n",
    "\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "salary: >50K,<=50K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273ca7f",
   "metadata": {},
   "source": [
    "### Step1: Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4cbcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from sklearn import preprocessing \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from __future__ import print_function\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "import tensorflow as tf2\n",
    "from tensorflow import keras\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994eebeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step2: Load the data, clean and prepare data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c278779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"census_final_df.csv\") # change this path depending on where you store the file on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46148eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>WORKCLASS</th>\n",
       "      <th>FNLWGT</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>EDUCATION-NUM</th>\n",
       "      <th>MARITAL_STATUS</th>\n",
       "      <th>OCCUPATION</th>\n",
       "      <th>RELATIONSHIP</th>\n",
       "      <th>RACE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CAPITAL_GAIN</th>\n",
       "      <th>CAPITAL_LOSS</th>\n",
       "      <th>HOURS_PER_WEEK</th>\n",
       "      <th>NATIVE_COUNTRY</th>\n",
       "      <th>INCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  WORKCLASS  FNLWGT  EDUCATION  EDUCATION-NUM  MARITAL_STATUS   \n",
       "0   39          6   77516          9             13               4  \\\n",
       "1   50          5   83311          9             13               2   \n",
       "2   38          3  215646         11              9               0   \n",
       "3   53          3  234721          1              7               2   \n",
       "4   28          3  338409          9             13               2   \n",
       "\n",
       "   OCCUPATION  RELATIONSHIP  RACE  SEX  CAPITAL_GAIN  CAPITAL_LOSS   \n",
       "0           0             1     4    1          2174             0  \\\n",
       "1           3             0     4    1             0             0   \n",
       "2           5             1     4    1             0             0   \n",
       "3           5             0     2    1             0             0   \n",
       "4           9             5     2    0             0             0   \n",
       "\n",
       "   HOURS_PER_WEEK  NATIVE_COUNTRY  INCOME  \n",
       "0              40              38       0  \n",
       "1              13              38       0  \n",
       "2              40              38       0  \n",
       "3              40              38       0  \n",
       "4              40               4       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5fcd7",
   "metadata": {},
   "source": [
    "### Step3: Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d987e6c5",
   "metadata": {},
   "source": [
    "Split data into a 70/30 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7111c38-a649-410b-8b43-9a8d39550a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(final_df, test_size=0.3)\n",
    "target = 'INCOME'\n",
    "predictors = ['AGE','EDUCATION','EDUCATION-NUM','MARITAL_STATUS','OCCUPATION','RELATIONSHIP','RACE','SEX','CAPITAL_GAIN','CAPITAL_LOSS','HOURS_PER_WEEK']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10aac6f6-69e4-42f7-957e-232732c8884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df[predictors]\n",
    "train_y = train_df[target]\n",
    "test_X = test_df[predictors]\n",
    "test_y = test_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23a3f9-f1b0-42fb-a786-cafdb6566c49",
   "metadata": {},
   "source": [
    "## 4. Model the data\n",
    "\n",
    "First, we will create a dataframe to hold all the results of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e73a7f-97e6-4998-9c21-875fb1dd6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ffb62b-e512-4a15-a3d7-94dc46bd4f2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Fit and test a Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7be09b-a697-4bb4-b12c-5f088dc5057e",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION MODEL- PARAMETER TUNING USING RANDSOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98880257-8ad6-4bd4-8713-d98ba71214ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.7872322823075679\n",
      "... with parameters: {'solver': 'lbfgs', 'penalty': 'none'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "\n",
    "\n",
    "\n",
    "log_reg_model = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(log_reg_model, space, n_iter=500, scoring='recall', n_jobs=-1, cv=kfolds, random_state=1)\n",
    "_ = rand_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecall = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c87a1a-2736-48da-ace5-ec9c4a2c5f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(test_y, rand_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random search_logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "#print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc19d1b-b7a1-4a4d-a8c4-2f95be99b272",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION MODEL- PARAMETER TUNING USING GRID SEARCH "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa3ede-ac7a-4780-9b8a-ba43e5926dce",
   "metadata": {},
   "source": [
    "Conduct an exhaustive search across a smaller range of parameters around the parameters found in the initial random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce6c07e9-04c4-4f7b-8439-a2418a9d9ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1350 candidates, totalling 2700 fits\n",
      "The best recall score is 0.858883015398759\n",
      "... with parameters: {'C': 0.0009540954763499944, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "    'C' : np.logspace(-4, 4),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear'],\n",
    "    'max_iter' : [100,200, 1000,]\n",
    "    }\n",
    "]\n",
    "\n",
    "log_reg_model = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = log_reg_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecall = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "923b1484-33dd-4516-9807-d148cb489cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search_logistic</td>\n",
       "      <td>0.736246</td>\n",
       "      <td>0.706604</td>\n",
       "      <td>0.795653</td>\n",
       "      <td>0.748489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search_logistic</td>\n",
       "      <td>0.736988</td>\n",
       "      <td>0.704173</td>\n",
       "      <td>0.804948</td>\n",
       "      <td>0.751196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  Accuracy  Precision    Recall        F1\n",
       "0  Random search_logistic  0.736246   0.706604  0.795653  0.748489\n",
       "0    Grid search_logistic  0.736988   0.704173  0.804948  0.751196"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Grid search_logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac4590-8c37-40a0-b28d-8962a75fd92e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SVM MODEL-PARAMETER TUNING USING RANDSOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a80f48bf-fe20-437a-ae17-6e2979e4694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "The best recall score is 1.0\n",
      "... with parameters: {'random_state': 1, 'kernel': 'rbf', 'gamma': 1, 'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "svm_param = {\n",
    "    \"C\": [.01, .1, 1,],\n",
    "    \"gamma\": [.01, .1, 1,],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"random_state\": [1]\n",
    "}\n",
    "\n",
    "svm_lin_model = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = svm_lin_model, param_distributions=svm_param, cv=kfolds, n_iter=200,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecall = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06951a42-54f0-4d43-b315-203b2cfa59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(test_y, rand_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random search_SVC\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "#print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcac426-fe68-4b4b-a131-d84eab6e72ee",
   "metadata": {},
   "source": [
    "### SVM MODEL- PARAMETER TUNING USING GRID SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da981fca-74eb-4421-95f6-3c72df9ac337",
   "metadata": {},
   "source": [
    "Conduct an exhaustive search across a smaller range of parameters around the parameters found in the initial random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1817fdd8-fd9f-435b-bc07-6bc7150c911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The best recall score is 0.9913814401331364\n",
      "... with parameters: {'C': 0.1, 'gamma': 2, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {'C': [0.1, 1], \n",
    "              'gamma': [2,1, 0.1],\n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "svm_lin_model = SVC()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = svm_lin_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecall = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9cdfaf7-6a4e-4b45-b179-97293b8b5964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search_logistic</td>\n",
       "      <td>0.736246</td>\n",
       "      <td>0.706604</td>\n",
       "      <td>0.795653</td>\n",
       "      <td>0.748489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search_logistic</td>\n",
       "      <td>0.736988</td>\n",
       "      <td>0.704173</td>\n",
       "      <td>0.804948</td>\n",
       "      <td>0.751196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search_SVC</td>\n",
       "      <td>0.493258</td>\n",
       "      <td>0.493258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search_SVC</td>\n",
       "      <td>0.682309</td>\n",
       "      <td>0.612145</td>\n",
       "      <td>0.971432</td>\n",
       "      <td>0.751030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  Accuracy  Precision    Recall        F1\n",
       "0  Random search_logistic  0.736246   0.706604  0.795653  0.748489\n",
       "0    Grid search_logistic  0.736988   0.704173  0.804948  0.751196\n",
       "0       Random search_SVC  0.493258   0.493258  1.000000  0.660647\n",
       "0         Grid search_SVC  0.682309   0.612145  0.971432  0.751030"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Grid search_SVC\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4b6098-1205-4b7f-948f-fba7d4c4942b",
   "metadata": {},
   "source": [
    "### DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a0cd4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b3b31f3-ccbe-46a7-99c9-3e2482b12f64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(train_X, train_y)\n",
    "dtree_prediction_output = dtree.predict(test_X)\n",
    "dtree_prediction_output[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68232dec-52df-494b-9d06-adc92cabe5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6813, 1: 8019}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(dtree_prediction_output, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f26c557-fceb-4f95-ad63-ec037064c47b",
   "metadata": {},
   "source": [
    "The above output means that we found 8019 of the 14832 observations in the validation set to be likely to have income more than 50K."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07db55f-91f8-44f0-8b04-846ad757205c",
   "metadata": {},
   "source": [
    "#### CONFUSION MATRIX - DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "535ed65f-62c3-4e00-bf0a-c66cfec9aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(test_y, dtree_prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b517c33-20a7-47ac-b875-b161527c348c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6322, 1194],\n",
       "       [ 491, 6825]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c074986-ebce-4c4d-8f33-511d9cca69e3",
   "metadata": {},
   "source": [
    "**TRUE POSITIVE:** Adults whose salary>50K and model actually predicted as salary>50K$ ie 6825\n",
    "\n",
    "**TRUE NEGATIVE:** Adults whose salary>50K but model not predicted as salary>50K$ ie 6322\n",
    "\n",
    "**FALSE POSITIVE:** Adults whose salary is not greater than 50K and model actually predicted as salary>50K$ ie 1194\n",
    "\n",
    "**FALSE NEGATIVE:** Adults whose salary>50K and model actually predicted as not-greater than 50k$ ie 491"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99322f6d-6822-4696-81bb-8bea73f8c044",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DECISION TREE-PARAMETER TUNING USING RANDSOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c316eda3-1cbb-4033-a7dd-7abe487f0fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.9274885503240909\n",
      "... with parameters: {'min_samples_split': 6, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 8, 'max_depth': 2, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,10),  \n",
    "    'min_samples_leaf': np.arange(1,10),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.0002),\n",
    "    'max_leaf_nodes': np.arange(5, 10), \n",
    "    'max_depth': np.arange(1,5), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecall = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1d22496-0cdb-46c0-a169-dafcd6a04535",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(test_y, rand_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random search_dtree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "#print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670f5441-3ae2-447e-9366-6d385896181e",
   "metadata": {},
   "source": [
    "### DECISION TREE-PARAMETER TUNING USING GRID SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8327dff8-36a5-42f3-b873-a6c9e7c5c3b5",
   "metadata": {},
   "source": [
    "Conduct an exhaustive search across a smaller range of parameters around the parameters found in the initial random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "740d80b1-de36-41dd-9c97-f06155fc74d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "The best recall score is 0.9274885503240909\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 2, 'max_leaf_nodes': 5, 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 1, 'min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(4,8),  \n",
    "    'min_samples_leaf': np.arange(1,3),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.0002),\n",
    "    'max_leaf_nodes': np.arange(5, 10), \n",
    "    'max_depth': np.arange(2,4), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecall = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0a67bf6-121a-4a50-852e-493eba0c6f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search_logistic</td>\n",
       "      <td>0.736246</td>\n",
       "      <td>0.706604</td>\n",
       "      <td>0.795653</td>\n",
       "      <td>0.748489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search_logistic</td>\n",
       "      <td>0.736988</td>\n",
       "      <td>0.704173</td>\n",
       "      <td>0.804948</td>\n",
       "      <td>0.751196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search_SVC</td>\n",
       "      <td>0.493258</td>\n",
       "      <td>0.493258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search_SVC</td>\n",
       "      <td>0.682309</td>\n",
       "      <td>0.612145</td>\n",
       "      <td>0.971432</td>\n",
       "      <td>0.751030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search_dtree</td>\n",
       "      <td>0.719188</td>\n",
       "      <td>0.648143</td>\n",
       "      <td>0.942182</td>\n",
       "      <td>0.767979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search_dtree</td>\n",
       "      <td>0.719188</td>\n",
       "      <td>0.648143</td>\n",
       "      <td>0.942182</td>\n",
       "      <td>0.767979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  Accuracy  Precision    Recall        F1\n",
       "0  Random search_logistic  0.736246   0.706604  0.795653  0.748489\n",
       "0    Grid search_logistic  0.736988   0.704173  0.804948  0.751196\n",
       "0       Random search_SVC  0.493258   0.493258  1.000000  0.660647\n",
       "0         Grid search_SVC  0.682309   0.612145  0.971432  0.751030\n",
       "0     Random search_dtree  0.719188   0.648143  0.942182  0.767979\n",
       "0       Grid search_dtree  0.719188   0.648143  0.942182  0.767979"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Grid search_dtree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e0d87-8e2a-4832-b458-77c2300c6d55",
   "metadata": {},
   "source": [
    "## 5.0 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77870505-378c-43b9-8118-5346597d62a6",
   "metadata": {},
   "source": [
    "Sorted by RECALL, the best models are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90bc26f7-c7aa-44af-9ab1-3f05d8acae23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search_logistic</td>\n",
       "      <td>0.736246</td>\n",
       "      <td>0.706604</td>\n",
       "      <td>0.795653</td>\n",
       "      <td>0.748489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search_logistic</td>\n",
       "      <td>0.736988</td>\n",
       "      <td>0.704173</td>\n",
       "      <td>0.804948</td>\n",
       "      <td>0.751196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search_dtree</td>\n",
       "      <td>0.719188</td>\n",
       "      <td>0.648143</td>\n",
       "      <td>0.942182</td>\n",
       "      <td>0.767979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search_dtree</td>\n",
       "      <td>0.719188</td>\n",
       "      <td>0.648143</td>\n",
       "      <td>0.942182</td>\n",
       "      <td>0.767979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search_SVC</td>\n",
       "      <td>0.682309</td>\n",
       "      <td>0.612145</td>\n",
       "      <td>0.971432</td>\n",
       "      <td>0.751030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search_SVC</td>\n",
       "      <td>0.493258</td>\n",
       "      <td>0.493258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  Accuracy  Precision    Recall        F1\n",
       "0  Random search_logistic  0.736246   0.706604  0.795653  0.748489\n",
       "0    Grid search_logistic  0.736988   0.704173  0.804948  0.751196\n",
       "0     Random search_dtree  0.719188   0.648143  0.942182  0.767979\n",
       "0       Grid search_dtree  0.719188   0.648143  0.942182  0.767979\n",
       "0         Grid search_SVC  0.682309   0.612145  0.971432  0.751030\n",
       "0       Random search_SVC  0.493258   0.493258  1.000000  0.660647"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa4931-5c33-4017-a8d7-ee78b80cd1ca",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "830048d9-c9fa-4ba2-8a8a-f5c5c125fef7",
   "metadata": {
    "id": "5WfGTWb3hYd-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 58s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c889fe12-101a-4372-9929-61159e569588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 41 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "669f349c-4f08-4054-b34a-52f9e561671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81      7516\n",
      "           1       0.77      0.90      0.83      7316\n",
      "\n",
      "    accuracy                           0.82     14832\n",
      "   macro avg       0.83      0.82      0.82     14832\n",
      "weighted avg       0.83      0.82      0.82     14832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365a31b-0d7a-46cf-b1c1-1b732aed8296",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLP CLASSIFIER- With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4550c99-c8a8-40eb-8bd8-374e4bfe3750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'sgd', 'max_iter': 5000, 'learning_rate_init': 0.01, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (60, 40, 20), 'alpha': 0.7, 'activation': 'logistic'}\n",
      "CPU times: total: 37.6 s\n",
      "Wall time: 1h 19min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac7c60d8-05e2-4d3c-964f-e4bd541196fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      7516\n",
      "           1       0.49      1.00      0.66      7316\n",
      "\n",
      "    accuracy                           0.49     14832\n",
      "   macro avg       0.25      0.50      0.33     14832\n",
      "weighted avg       0.24      0.49      0.33     14832\n",
      "\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 124 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a446966-7f1f-4e83-887f-2a5d05b8a01c",
   "metadata": {},
   "source": [
    "## MLP CLASSIFIER -With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "582c3d92-8d65-4d44-95f9-9a09a01bc7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "{'activation': 'tanh', 'alpha': 0.5, 'hidden_layer_sizes': (70,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 6.8 s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (70,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [ 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccee9f6a-4df4-49e7-af79-4266ed05f732",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.67      0.77      7516\n",
      "           1       0.73      0.93      0.82      7316\n",
      "\n",
      "    accuracy                           0.79     14832\n",
      "   macro avg       0.82      0.80      0.79     14832\n",
      "weighted avg       0.82      0.79      0.79     14832\n",
      "\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 65.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd592dac",
   "metadata": {},
   "source": [
    "### Summary of Evaluation Metrics for the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cfaa80-858f-40c3-a074-eee9e05e8945",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metrics Considered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e2ee6-4142-45b5-a945-5f66b91bc5c1",
   "metadata": {},
   "source": [
    "### Results\n",
    "### 1. SVM Tuning Model predicted (97.54%-94.21%) = 3.33% better than Decision Tree Tuning model, but the recall score of random search in SVM model gives us 100% that tell us SVM tuning model is overfitting the data and Logistic regression tuning model predicted 80% of adults having greater than 50k$\n",
    "\n",
    "### 2. When Decision Tree Tuning Model predicted salary greater than 50K$, Dtree is correct 94.2% of the time using Grid Search , where as Logistic regression Tuning Model is correct only 80% time.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f00c8",
   "metadata": {},
   "source": [
    " As there is a significant huge amount of False Positives we are considering recall as evaluation metrics.\n",
    "\n",
    "3. Based on the above values of recall we can say that the Hyperparameter tuned dtree model outperformed the Tuned Logistic and svm model.\n",
    "\n",
    "\n",
    "**Recall:** Interms of Recall, decision tree Tuned Model performed better than logistic regression  model and there is an overfitting in svm model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c849b2-cb9a-403f-8524-477c76a7a008",
   "metadata": {},
   "source": [
    "### when we compare the results of the evaluation metrics of logistic, SVM and Decision Tree with Neural Networks we got the recall score of 0.84 where as the recall score of decision tree was 0.94~ 94%\n",
    "### The recall score of Neural Networks (84%) is more than the recall score of Logistic regression (80%) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
